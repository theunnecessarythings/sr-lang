package main

liger_group_norm :: import "vendor/liger_group_norm"
triton :: import "vendor/triton"
cuda :: import "vendor/cuda"
io :: import "std/io"
alloc :: import "std/alloc"
math :: import "std/math"

PtrF32 :: triton.Ptr(f32)

main :: proc() {
    res := cuda.cuInit(0)
    if res != cuda.SUCCESS {
        io.println("Failed to init CUDA: %d", res)
        return
    }

    dev: cuda.CUdevice = undefined
    res = cuda.cuDeviceGet(&dev, 0)
    if res != cuda.SUCCESS {
        io.println("Failed to get device", ())
        return
    }

    ctx: cuda.CUcontext = null
    res = cuda.cuCtxCreate(&ctx, 0, dev)
    if res != cuda.SUCCESS {
        io.println("Failed to create context", ())
        return
    }

    n_rows: i32 = 2
    n_groups: i32 = 2
    channels_per_group: i32 = 2
    hidden_size_per_channel: i32 = 8
    hidden_size: i32 = channels_per_group * hidden_size_per_channel

    row_stride: i32 = n_groups * hidden_size
    col_stride: i32 = hidden_size

    size := n_rows.(usize) * row_stride.(usize) * 4

    x_h_ptr := alloc.alloc(size) orelse return
    x_h := x_h_ptr.^*f32
    y_h_ptr := alloc.alloc(size) orelse return
    y_h := y_h_ptr.^*f32

    w_h_ptr := alloc.alloc((n_groups * channels_per_group).(usize) * 4) orelse return
    w_h := w_h_ptr.^*f32
    b_h_ptr := alloc.alloc((n_groups * channels_per_group).(usize) * 4) orelse return
    b_h := b_h_ptr.^*f32

    mean_h_ptr := alloc.alloc((n_rows * n_groups).(usize) * 4) orelse return
    mean_h := mean_h_ptr.^*f32
    rstd_h_ptr := alloc.alloc((n_rows * n_groups).(usize) * 4) orelse return
    rstd_h := rstd_h_ptr.^*f32

    i: i32 = 0
    total: i32 = n_rows * row_stride
    while i < total {
        x_h[i] = ((i % 31) - 15).(f32) * 0.02
        i = i + 1
    }

    i = 0
    while i < n_groups * channels_per_group {
        w_h[i] = ((i % 7) - 3).(f32) * 0.1 + 1.0
        b_h[i] = ((i % 5) - 2).(f32) * 0.05
        i = i + 1
    }

    eps: f32 = 1.e-5

    y_ref_ptr := alloc.alloc(size) orelse return
    y_ref := y_ref_ptr.^*f32
    mean_ref_ptr := alloc.alloc((n_rows * n_groups).(usize) * 4) orelse return
    mean_ref := mean_ref_ptr.^*f32
    rstd_ref_ptr := alloc.alloc((n_rows * n_groups).(usize) * 4) orelse return
    rstd_ref := rstd_ref_ptr.^*f32

    r: i32 = 0
    while r < n_rows {
        g: i32 = 0
        while g < n_groups {
            base := r * row_stride + g * hidden_size
            sum: f32 = 0.0
            c: i32 = 0
            while c < hidden_size {
                sum = sum + x_h[base + c]
                c = c + 1
            }
            mean := sum / hidden_size.(f32)
            mean_ref[r * n_groups + g] = mean
            var_sum: f32 = 0.0
            c = 0
            while c < hidden_size {
                v := x_h[base + c] - mean
                var_sum = var_sum + v * v
                c = c + 1
            }
            var := var_sum / hidden_size.(f32)
            rstd := 1.0.(f32) / math.sqrtf(var + eps)
            rstd_ref[r * n_groups + g] = rstd

            ch: i32 = 0
            while ch < channels_per_group {
                w := w_h[g * channels_per_group + ch]
                b := b_h[g * channels_per_group + ch]
                off := ch * hidden_size_per_channel
                c = 0
                while c < hidden_size_per_channel {
                    idx := base + off + c
                    y_ref[idx] = (x_h[idx] - mean) * rstd * w + b
                    c = c + 1
                }
                ch = ch + 1
            }
            g = g + 1
        }
        r = r + 1
    }

    x_d: cuda.CUdeviceptr = 0
    y_d: cuda.CUdeviceptr = 0
    w_d: cuda.CUdeviceptr = 0
    b_d: cuda.CUdeviceptr = 0
    mean_d: cuda.CUdeviceptr = 0
    rstd_d: cuda.CUdeviceptr = 0

    _ = cuda.cuMemAlloc(&x_d, size)
    _ = cuda.cuMemAlloc(&y_d, size)
    _ = cuda.cuMemAlloc(&w_d, (n_groups * channels_per_group).(usize) * 4)
    _ = cuda.cuMemAlloc(&b_d, (n_groups * channels_per_group).(usize) * 4)
    _ = cuda.cuMemAlloc(&mean_d, (n_rows * n_groups).(usize) * 4)
    _ = cuda.cuMemAlloc(&rstd_d, (n_rows * n_groups).(usize) * 4)

    _ = cuda.cuMemcpyHtoD(x_d, x_h.^?*void, size)
    _ = cuda.cuMemcpyHtoD(w_d, w_h.^?*void, (n_groups * channels_per_group).(usize) * 4)
    _ = cuda.cuMemcpyHtoD(b_d, b_h.^?*void, (n_groups * channels_per_group).(usize) * 4)

    triton.launch(
        liger_group_norm.group_norm_forward_kernel,
        grid = (n_rows, n_groups, 1),
        block = (128, 1, 1),
        BLOCK_SIZE = 32,
        y_d,
        row_stride,
        col_stride,
        x_d,
        row_stride,
        col_stride,
        mean_d,
        n_groups,
        1,
        rstd_d,
        n_groups,
        1,
        w_d,
        b_d,
        hidden_size,
        channels_per_group,
        eps,
    )

    _ = cuda.cuMemcpyDtoH(y_h.^?*void, y_d, size)
    _ = cuda.cuMemcpyDtoH(mean_h.^?*void, mean_d, (n_rows * n_groups).(usize) * 4)
    _ = cuda.cuMemcpyDtoH(rstd_h.^?*void, rstd_d, (n_rows * n_groups).(usize) * 4)

    success := true
    epsilon: f32 = 1.e-3
    i = 0
    while i < total {
        diff := y_h[i] - y_ref[i]
        if diff < 0 { diff = -diff }
        if diff > epsilon {
            io.println("y mismatch at %d: expected %f got %f", i, y_ref[i], y_h[i])
            success = false
            break
        }
        i = i + 1
    }

    i = 0
    while i < n_rows * n_groups and success {
        diffm := mean_h[i] - mean_ref[i]
        if diffm < 0 { diffm = -diffm }
        if diffm > 5.e-4 {
            io.println("mean mismatch at %d: expected %f got %f", i, mean_ref[i], mean_h[i])
            success = false
            break
        }
        diffr := rstd_h[i] - rstd_ref[i]
        if diffr < 0 { diffr = -diffr }
        if diffr > 5.e-4 {
            io.println("rstd mismatch at %d: expected %f got %f", i, rstd_ref[i], rstd_h[i])
            success = false
            break
        }
        i = i + 1
    }

    if success { io.println("GroupNorm forward verification passed", ()) }

    _ = cuda.cuMemFree(x_d)
    _ = cuda.cuMemFree(y_d)
    _ = cuda.cuMemFree(w_d)
    _ = cuda.cuMemFree(b_d)
    _ = cuda.cuMemFree(mean_d)
    _ = cuda.cuMemFree(rstd_d)
}
